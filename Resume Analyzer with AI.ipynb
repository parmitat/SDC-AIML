{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOOwRV3MAxVpp9A8P39JrPA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HarsikaVetrivel/PYTHONAIML/blob/main/resume.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install langchain openai pdfminer.six python-docx\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Aey4YFshPRWR",
        "outputId": "e5470729-0620-46c5-955d-b3b2870c8866"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.3.23)\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.11/dist-packages (1.70.0)\n",
            "Collecting pdfminer.six\n",
            "  Downloading pdfminer_six-20250327-py3-none-any.whl.metadata (4.1 kB)\n",
            "Collecting python-docx\n",
            "  Downloading python_docx-1.1.2-py3-none-any.whl.metadata (2.0 kB)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.51 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.51)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.8)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.24)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.11.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.0.40)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.9.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.11/dist-packages (from openai) (4.13.1)\n",
            "Requirement already satisfied: charset-normalizer>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from pdfminer.six) (3.4.1)\n",
            "Requirement already satisfied: cryptography>=36.0.0 in /usr/local/lib/python3.11/dist-packages (from pdfminer.six) (43.0.3)\n",
            "Requirement already satisfied: lxml>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from python-docx) (5.3.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.11/dist-packages (from cryptography>=36.0.0->pdfminer.six) (1.17.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.51->langchain) (9.1.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.51->langchain) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.51->langchain) (24.2)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (3.10.16)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2.3.0)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six) (2.22)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.51->langchain) (3.0.0)\n",
            "Downloading pdfminer_six-20250327-py3-none-any.whl (5.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m36.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_docx-1.1.2-py3-none-any.whl (244 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m244.3/244.3 kB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: python-docx, pdfminer.six\n",
            "Successfully installed pdfminer.six-20250327 python-docx-1.1.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%env OPENAI_API_KEY=\"your-api-key\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BjL02cGgPZSC",
        "outputId": "0465c53e-5883-4243-9142-b88c111579bb"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "env: OPENAI_API_KEY=\"your-api-key\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import openai\n",
        "from langchain.prompts import ChatPromptTemplate\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.chains import LLMChain\n",
        "from pdfminer.high_level import extract_text\n",
        "from docx import Document\n",
        "\n",
        "# Initialize OpenAI GPT model using LangChain\n",
        "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\")\n",
        "\n",
        "# Create prompt template for resume analysis\n",
        "prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", \"You are an expert resume evaluator. Provide insights and suggestions for improvement.\"),\n",
        "    (\"human\", \"Analyze the following resume and provide feedback and suggestions:\\n\\n{resume_text}\")\n",
        "])\n",
        "\n",
        "# Create resume analysis chain\n",
        "chain = LLMChain(llm=llm, prompt=prompt)\n",
        "\n",
        "# Function to extract text from PDF\n",
        "def extract_pdf_text(pdf_path):\n",
        "    return extract_text(pdf_path)\n",
        "\n",
        "# Function to extract text from Word document\n",
        "def extract_docx_text(docx_path):\n",
        "    doc = Document(docx_path)\n",
        "    return '\\n'.join([para.text for para in doc.paragraphs])\n",
        "\n",
        "# Function to analyze the resume\n",
        "def analyze_resume(resume_text):\n",
        "    return chain.run({\"resume_text\": resume_text})\n",
        "\n",
        "# Main function to handle resume input\n",
        "def process_resume(file_path):\n",
        "    file_extension = file_path.split('.')[-1].lower()\n",
        "\n",
        "    if file_extension == 'pdf':\n",
        "        resume_text = extract_pdf_text(file_path)\n",
        "    elif file_extension == 'docx':\n",
        "        resume_text = extract_docx_text(file_path)\n",
        "    else:\n",
        "        with open(file_path, 'r') as file:\n",
        "            resume_text = file.read()\n",
        "\n",
        "    # Analyzing the resume\n",
        "    feedback = analyze_resume(resume_text)\n",
        "    return feedback\n",
        "\n",
        "# Example Usage\n",
        "if __name__ == \"__main__\":\n",
        "    resume_file = input(\"Enter the path to the resume file (PDF, DOCX, or Text): \")\n",
        "    feedback = process_resume(resume_file)\n",
        "    print(\"\\nFeedback & Suggestions:\")\n",
        "    print(feedback)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        },
        "id": "m2ia9bIBPeu9",
        "outputId": "19fd3722-d2ab-4a2f-ac46-4cef995df09c"
      },
      "execution_count": 29,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter the path to the resume file (PDF, DOCX, or Text): Text\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'Text'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-29-981126020982>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mresume_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Enter the path to the resume file (PDF, DOCX, or Text): \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     \u001b[0mfeedback\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess_resume\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresume_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nFeedback & Suggestions:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeedback\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-29-981126020982>\u001b[0m in \u001b[0;36mprocess_resume\u001b[0;34m(file_path)\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0mresume_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_docx_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m             \u001b[0mresume_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Text'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import openai\n",
        "from langchain.prompts import ChatPromptTemplate\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.chains import LLMChain\n",
        "from pdfminer.high_level import extract_text\n",
        "from docx import Document\n",
        "\n",
        "# Initialize OpenAI GPT model using LangChain\n",
        "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\")\n",
        "\n",
        "# Create prompt template for resume analysis\n",
        "prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", \"You are an expert resume evaluator. Provide insights and suggestions for improvement.\"),\n",
        "    (\"human\", \"Analyze the following resume and provide feedback and suggestions:\\n\\n{resume_text}\")\n",
        "])\n",
        "\n",
        "# Create resume analysis chain\n",
        "chain = LLMChain(llm=llm, prompt=prompt)\n",
        "\n",
        "# Function to extract text from PDF\n",
        "def extract_pdf_text(pdf_path):\n",
        "    return extract_text(pdf_path)\n",
        "\n",
        "# Function to extract text from Word document\n",
        "def extract_docx_text(docx_path):\n",
        "    doc = Document(docx_path)\n",
        "    return '\\n'.join([para.text for para in doc.paragraphs])\n",
        "\n",
        "# Function to analyze the resume\n",
        "def analyze_resume(resume_text):\n",
        "    return chain.run({\"resume_text\": resume_text})\n",
        "\n",
        "# Main function to handle resume input\n",
        "def process_resume(file_path):\n",
        "    file_extension = file_path.split('.')[-1].lower()\n",
        "\n",
        "    if file_extension == 'pdf':\n",
        "        resume_text = extract_pdf_text(file_path)\n",
        "    elif file_extension == 'docx':\n",
        "        resume_text = extract_docx_text(file_path)\n",
        "    else:\n",
        "        with open(file_path, 'r') as file: # This line was causing the error because 'Text' is not a valid file path.\n",
        "            resume_text = file.read()\n",
        "\n",
        "    # Analyzing the resume\n",
        "    feedback = analyze_resume(resume_text)\n",
        "    return feedback\n",
        "\n",
        "# Example Usage\n",
        "if __name__ == \"__main__\":\n",
        "    resume_file = input(\"Enter the path to the resume file (PDF, DOCX, or Text file with extension): \") # Changed the input prompt to be more specific.\n",
        "    feedback = process_resume(resume_file)\n",
        "    print(\"\\nFeedback & Suggestions:\")\n",
        "    print(feedback)"
      ],
      "metadata": {
        "id": "s8sQm7MrPsdH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
